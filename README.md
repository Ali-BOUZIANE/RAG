# ğŸ¤– Projet RAG : Questionâ€“RÃ©ponse sur PDF avec LangChain, Ollama et Chroma

## ğŸ“Œ Description du Projet

Ce projet met en Å“uvre une architecture **RAG (Retrieval-Augmented Generation)** permettant dâ€™interroger le contenu dâ€™un **document PDF** Ã  lâ€™aide dâ€™un **modÃ¨le de langage local**.

Lâ€™approche combine :
- La **recherche sÃ©mantique** (embeddings + base vectorielle).
- La **gÃ©nÃ©ration de texte** par un LLM (Large Language Model).

L'objectif est de produire des **rÃ©ponses prÃ©cises et contextualisÃ©es**, basÃ©es uniquement sur les informations contenues dans le document source, garantissant ainsi la confidentialitÃ© et la fiabilitÃ© des donnÃ©es.

Le projet utilise **LangChain** pour lâ€™orchestration, **Ollama** pour lâ€™exÃ©cution locale du modÃ¨le **Mistral**, et **ChromaDB** comme base de donnÃ©es vectorielle.

---

## ğŸ¯ Objectifs

* **Charger et analyser** un document PDF complexe.
* **Segmenter le texte** en unitÃ©s exploitables (chunks).
* **GÃ©nÃ©rer des embeddings** (vecteurs numÃ©riques) pour chaque segment.
* **Indexer les donnÃ©es** dans une base de donnÃ©es vectorielle performante.
* **Effectuer une recherche sÃ©mantique** pour retrouver le contexte pertinent.
* **GÃ©nÃ©rer des rÃ©ponses** via un LLM local sans dÃ©pendance au cloud.
* **DÃ©ployer un pipeline RAG** fonctionnel de bout en bout.

---

## ğŸ§  Architecture du SystÃ¨me

Le flux d'informations suit le schÃ©ma suivant :

**Document PDF** â®• **DÃ©coupage (Splitter)** â®• **Embeddings** â®• **ChromaDB** â®• **Similarity Search** â®• **LLM (Mistral)** â®• **RÃ©ponse finale**

---

## ğŸ› ï¸ Technologies UtilisÃ©es

* **Langage :** Python
* **Orchestrateur :** LangChain
* **Moteur LLM :** Ollama (ModÃ¨le : Mistral)
* **Vector Store :** ChromaDB
* **Parser PDF :** PyPDF
* **Embeddings :** OllamaEmbeddings (modÃ¨le local)

---

## ğŸ“¦ Installation & Configuration

### 1. Installation des dÃ©pendances
```bash
pip install -U langchain langchain-community chromadb pypdf ollama
2. Configuration d'Ollama
Assurez-vous qu'Ollama est installÃ© sur votre machine, puis tÃ©lÃ©chargez le modÃ¨le requis :

Bash
# VÃ©rifier l'installation
ollama list

# TÃ©lÃ©charger le modÃ¨le Mistral
ollama pull mistral
âš™ï¸ DÃ©tails du Pipeline Technique
ğŸ“„ Traitement du Document
Le texte est extrait avec PyPDFLoader puis dÃ©coupÃ© avec RecursiveCharacterTextSplitter pour conserver la cohÃ©rence sÃ©mantique.

Taille des segments (chunk_size) : 500 caractÃ¨res.

Chevauchement (overlap) : 50 caractÃ¨res pour Ã©viter la perte de contexte entre les segments.


ğŸ§¬ Indexation & Persistance
Les embeddings sont gÃ©nÃ©rÃ©s localement. La base de donnÃ©es ChromaDB est configurÃ©e pour Ãªtre persistante dans le dossier ./rag_db, Ã©vitant ainsi de rÃ©-indexer le document Ã  chaque exÃ©cution.


ğŸ” Recherche & GÃ©nÃ©ration
Le systÃ¨me utilise la recherche par similaritÃ© pour extraire les passages les plus pertinents du PDF. Ces passages sont ensuite injectÃ©s dans un prompt structurÃ© envoyÃ© Ã  Mistral pour produire la rÃ©ponse.


âœ… RÃ©sultats et Validation
Le pipeline a Ã©tÃ© validÃ© avec succÃ¨s sur un document technique relatif Ã  l'Ã©cosystÃ¨me Oracle. Le modÃ¨le a Ã©tÃ© capable d'expliquer avec prÃ©cision :

L'architecture de l'entreprise et de la base de donnÃ©es Oracle.

Le fonctionnement de Oracle Forms & Reports.

L'utilisation de SQL*Plus et du langage PL/SQL.


ğŸ“‚ Structure du Projet
Plaintext
.
â”œâ”€â”€ rag_db/                 # Base de donnÃ©es vectorielle persistante
â”œâ”€â”€ main.py                 # Script Python principal (Logique RAG)
â”œâ”€â”€ ORACLE.pdf              # Document source analysÃ©
â””â”€â”€ README.md               # Documentation complÃ¨te


ğŸ‘¨â€ğŸ’» Auteur
Ali Bouziane IngÃ©nieur en GÃ©nie Informatique | IA, Big Data & CybersÃ©curitÃ© ğŸ“§ bouziane_ali@upf.ac.ma ğŸ”— LinkedIn
